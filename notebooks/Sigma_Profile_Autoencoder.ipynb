{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0 Solvent FileHandle   index_0   index_1   index_2  \\\n",
      "0            1850   water    0044met  0.000400  0.100000  0.000525   \n",
      "1            2818   water    0076but  0.000400  0.100000  0.000525   \n",
      "2            2818   water    0076but  0.000400  0.100000  0.000525   \n",
      "3            4824   water    0062dio  0.000400  0.100000  0.000525   \n",
      "4            5208   water    0086eth  0.000400  0.100000  0.000525   \n",
      "...           ...     ...        ...       ...       ...       ...   \n",
      "80195        5430   water    0217wat  0.005504  0.722813  0.003820   \n",
      "80196        2678   water    0076but  0.005504  0.722813  0.003820   \n",
      "80197        4685   water    0062dio  0.005504  0.722813  0.003820   \n",
      "80198        2678   water    0076but  0.005504  0.722813  0.003820   \n",
      "80199        2678   water    0076but  0.005504  0.722813  0.003820   \n",
      "\n",
      "       Solvation_Energy  Total_Energy   No.   SoluteName  ...  \\\n",
      "0             -0.080986    -30.286090  2133     methanol  ...   \n",
      "1             -0.005511    -72.519841  2163   2-butanone  ...   \n",
      "2             -0.005511    -72.519841  2163   2-butanone  ...   \n",
      "3              0.041709    -78.154816  2150  1,4-dioxane  ...   \n",
      "4             -0.073923    -46.819352  2173   aceticacid  ...   \n",
      "...                 ...           ...   ...          ...  ...   \n",
      "80195         -0.515908    -14.743518  2285        water  ...   \n",
      "80196         -0.017638    -72.531904  2163   2-butanone  ...   \n",
      "80197         -0.008190    -78.204647  2150  1,4-dioxane  ...   \n",
      "80198         -0.017638    -72.531904  2163   2-butanone  ...   \n",
      "80199         -0.017638    -72.531904  2163   2-butanone  ...   \n",
      "\n",
      "      sigma_solvent_45 sigma_solvent_46  sigma_solvent_47  sigma_solvent_48  \\\n",
      "0                  0.0              0.0               0.0               0.0   \n",
      "1                  0.0              0.0               0.0               0.0   \n",
      "2                  0.0              0.0               0.0               0.0   \n",
      "3                  0.0              0.0               0.0               0.0   \n",
      "4                  0.0              0.0               0.0               0.0   \n",
      "...                ...              ...               ...               ...   \n",
      "80195              0.0              0.0               0.0               0.0   \n",
      "80196              0.0              0.0               0.0               0.0   \n",
      "80197              0.0              0.0               0.0               0.0   \n",
      "80198              0.0              0.0               0.0               0.0   \n",
      "80199              0.0              0.0               0.0               0.0   \n",
      "\n",
      "       sigma_solvent_49  sigma_solvent_50  default_error      NC_K   SIGMA_K  \\\n",
      "0                   0.0               0.0       0.632071  0.000400  0.100000   \n",
      "1                   0.0               0.0       0.556505  0.000400  0.100000   \n",
      "2                   0.0               0.0       0.556505  0.000400  0.100000   \n",
      "3                   0.0               0.0       1.469889  0.000400  0.100000   \n",
      "4                   0.0               0.0       0.540563  0.000400  0.100000   \n",
      "...                 ...               ...            ...       ...       ...   \n",
      "80195               0.0               0.0       0.896919  0.005504  0.722813   \n",
      "80196               0.0               0.0       0.556505  0.005504  0.722813   \n",
      "80197               0.0               0.0       1.469889  0.005504  0.722813   \n",
      "80198               0.0               0.0       0.556505  0.005504  0.722813   \n",
      "80199               0.0               0.0       0.556505  0.005504  0.722813   \n",
      "\n",
      "            TAU  \n",
      "0      0.000525  \n",
      "1      0.000525  \n",
      "2      0.000525  \n",
      "3      0.000525  \n",
      "4      0.000525  \n",
      "...         ...  \n",
      "80195  0.003820  \n",
      "80196  0.003820  \n",
      "80197  0.003820  \n",
      "80198  0.003820  \n",
      "80199  0.003820  \n",
      "\n",
      "[80200 rows x 177 columns]\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, Solvent, FileHandle, index_0, index_1, index_2, Solvation_Energy, Total_Energy, No., SoluteName, Formula, Subset, Charge, Level1, Level2, Level3, DeltaGsolv, type, eps, n, alpha, beta, gamma, phi**2, psi**2, beta**2, H, C, HC, CC, CC2, N, HN, HN2, CN, NC, NC2, NC3, O, HO, HO2, OC, CO2, ON, OO, F, Cl, Br, I, FC, ClC, BrC, IC, Si, OSi, P, HP, OP, S, HS, OS, SP, SS, TotalArea, error, error_ev, error_frac, area_solute, volume_solute, sigma_solute_0, sigma_solute_1, sigma_solute_2, sigma_solute_3, sigma_solute_4, sigma_solute_5, sigma_solute_6, sigma_solute_7, sigma_solute_8, sigma_solute_9, sigma_solute_10, sigma_solute_11, sigma_solute_12, sigma_solute_13, sigma_solute_14, sigma_solute_15, sigma_solute_16, sigma_solute_17, sigma_solute_18, sigma_solute_19, sigma_solute_20, sigma_solute_21, sigma_solute_22, sigma_solute_23, sigma_solute_24, sigma_solute_25, sigma_solute_26, sigma_solute_27, sigma_solute_28, sigma_solute_29, sigma_solute_30, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 177 columns]\n",
      "Number of groups:  401\n",
      "Number of groups to use for training:  396\n",
      "Number of groups to use for testing:  5\n",
      "401\n",
      "X_train shape: (79200, 57), y_train shape: (79200,)\n",
      "X_test shape: (1000, 57), y_test shape: (1000,)\n",
      "TRAINING SET DETAILS\n",
      "Number of observations: 79200\n",
      "Number of features: 57\n",
      "TESTING SET DETAILS\n",
      "Number of observations: 1000\n",
      "Number of features: 57\n",
      "(79200, 57)\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import COSMO_TL as ctl\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "import dask\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import interpn\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import  mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.optimize import curve_fit, minimize, differential_evolution\n",
    "# get particle swarm optimizer\n",
    "from pyswarm import pso\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import kmodels as kmk\n",
    "import shutil\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "def get_X_solute(df):\n",
    "    X = df[['volume_solute', 'area_solute', 'NC_K', 'SIGMA_K','TAU', 'default_error']]\n",
    "    sig_cols = [col for col in df.columns if 'sigma_solute' in col]\n",
    "    sigs = df[sig_cols].to_numpy()\n",
    "    X = X.to_numpy().reshape(len(df), -1)\n",
    "    X = np.column_stack((X, sigs))\n",
    "    return X\n",
    "\n",
    "def get_X_solvent(df):\n",
    "    X = df[['volume_solvent', 'area_solvent','NC_K','SIGMA_K','TAU', 'default_error']]\n",
    "    sig_cols = [col for col in df.columns if 'sigma_solvent' in col]\n",
    "    sigs = df[sig_cols].to_numpy()\n",
    "    X = X.to_numpy().reshape(len(df), -1)\n",
    "    X = np.column_stack((X, sigs))\n",
    "    return X\n",
    "\n",
    "def get_X(df):\n",
    "    X_solute = get_X_solute(df)\n",
    "    X_solvent = get_X_solvent(df)\n",
    "    # solvent prop cols = eps,n,alpha,beta,gamma,phi**2,psi**2,beta**2\n",
    "    solvent_props_names = ['eps', 'n', 'alpha', 'beta', 'gamma', 'phi**2', 'psi**2', 'beta**2']\n",
    "    solvent_props = df[solvent_props_names].to_numpy()\n",
    "    X = np.column_stack((X_solute, X_solvent, solvent_props))\n",
    "    return X\n",
    "# given a dataframe return a dataframe with the mean value for all columns with error in the name\n",
    "# grouped by SoluteName\n",
    "def get_mean_df(df):\n",
    "    df2 = df.copy()\n",
    "    original_columns = list(df2.columns)\n",
    "    print(original_columns)\n",
    "    cols = [col for col in df2.columns if 'error' in col]\n",
    "    original_columns = [col for col in original_columns if col not in cols]\n",
    "    df3 = df2.groupby(['SoluteName', 'NC_K','SIGMA_K','TAU'])[cols].mean()\n",
    "    df3 = df3.reset_index()\n",
    "    # return a dataframe with the unique values in SoluteName and the mean values for all columns with error in the name\n",
    "    # get all the other colums  from the original dataframe\n",
    "    df4 = df2[original_columns]\n",
    "    df4 = df4.reset_index(drop=True)\n",
    "    df5 = pd.merge(df4, df3, on=['SoluteName', 'NC_K','SIGMA_K','TAU'])\n",
    "    df5 = df5.drop_duplicates()\n",
    "    return df5\n",
    "\n",
    "csv_path = '/blue/hennig/ericfonseca/NASA/VASPsol/Truhlar_Benchmarks/VaspPysol/data/vaspsol_data_3_2_2023_balanced'\n",
    "\n",
    "#df = pd.read_csv(csv_path)\n",
    "df = dd.read_parquet(csv_path)\n",
    "df = df.compute()\n",
    "print(df)\n",
    "df['error'] = df['error'].abs()\n",
    "df = df[df['error'] < 10]\n",
    "df = df[df['Solvent'] == 'water']\n",
    "df = df[df['Charge'] == 0]\n",
    "NC_K_default = 0.0025\n",
    "SIGMA_K_default = 0.6\n",
    "TAU_default = 0.000525\n",
    "# default_df = df[(df['NC_K'] == NC_K_default) & (df['SIGMA_K'] == SIGMA_K_default) & (df['TAU'] == TAU_default)]\n",
    "# print(default_df)\n",
    "\n",
    "\n",
    "\n",
    "# df_to_append = default_df[['SoluteName','error']]\n",
    "# # rename error to default_error\n",
    "# df_to_append = df_to_append.rename(columns={'error': 'default_error'})\n",
    "# df_to_append\n",
    "\n",
    "\n",
    "# # match up the default error back to the original dataframe\n",
    "# df = pd.merge(df, df_to_append, on=['SoluteName'])\n",
    "# # this expanded the number of rows in the dataframe. This is not what we want\n",
    "#df = df.drop_duplicates('Unnamed: 0')\n",
    "\n",
    "groups = df[df['Solvent']=='water'].groupby(['NC_K', 'SIGMA_K', 'TAU'])\n",
    "# print(df)\n",
    "\n",
    "#df_test = pd.read_csv(csv_path)\n",
    "df_test = dd.read_parquet(csv_path)\n",
    "df_test = df_test.compute()\n",
    "# we want the NC_K, SIGMA_K and TAU combinations that are not in \n",
    "# the training set\n",
    "df_test = df_test[~df_test[['NC_K', 'SIGMA_K', 'TAU']].isin(df[['NC_K', 'SIGMA_K', 'TAU']]).all(axis=1)]\n",
    "default_df = df_test[(df_test['NC_K'] == NC_K_default) & (df_test['SIGMA_K'] == SIGMA_K_default) & (df_test['TAU'] == TAU_default)]\n",
    "print(default_df)\n",
    "\n",
    "# get the number of unique groups\n",
    "# using the groups split of the dataframe so that unique combos of NC_K, SIGMA_K, and TAU are in each group\n",
    "split = 0.99\n",
    "## get the unique groups\n",
    "#groups = df.groupby(['NC_K', 'SIGMA_K', 'TAU'])\n",
    "# get the indicies of the groups\n",
    "indicies = [np.array(i) for i in groups.indices.values()]\n",
    "# get the number of groups\n",
    "num_groups = len(indicies)\n",
    "print('Number of groups: ', num_groups)\n",
    "\n",
    "# get the number of groups to use for training\n",
    "num_train_groups = int(num_groups*split)\n",
    "print('Number of groups to use for training: ', num_train_groups)\n",
    "print('Number of groups to use for testing: ', num_groups - num_train_groups)\n",
    "# get the indicies of the groups to use for training\n",
    "print(len(indicies))\n",
    "\n",
    "idx_temp = np.arange(len(indicies))\n",
    "train_indicies = [indicies[i] for i in np.random.choice(idx_temp, size=num_train_groups, replace=False)]\n",
    "train_indicies = np.concatenate(train_indicies)\n",
    "# get the indicies of the groups to use for testing\n",
    "test_indicies = np.array([i for i in np.concatenate(indicies) if i not in train_indicies])\n",
    "train_df = df.iloc[train_indicies]\n",
    "test_df = df.iloc[test_indicies]\n",
    "\n",
    "X_train = get_X_solute(train_df)\n",
    "X_test = get_X_solute(test_df)\n",
    "y_train = train_df['error'].to_numpy()\n",
    "y_test = test_df['error'].to_numpy()\n",
    "X_test = get_X_solute(test_df)\n",
    "\n",
    "# print out the shape of the training data and the training labels. Nice retro looking print statment\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "n_observations_train = X_train.shape[0]\n",
    "n_features_train = X_train.shape[1]\n",
    "n_observations_test = X_test.shape[0]\n",
    "n_features_test = X_test.shape[1]\n",
    "\n",
    "print('TRAINING SET DETAILS')\n",
    "print(f'Number of observations: {n_observations_train}')\n",
    "print(f'Number of features: {n_features_train}')\n",
    "\n",
    "print('TESTING SET DETAILS')\n",
    "print(f'Number of observations: {n_observations_test}')\n",
    "print(f'Number of features: {n_features_test}')\n",
    "\n",
    "\n",
    "\n",
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape)\n",
    "# send the training data to gpu\n",
    "X_train = torch.from_numpy(X_train).float().reshape(-1, n_features_train)\n",
    "y_train = torch.from_numpy(y_train).float().reshape(-1, 1)\n",
    "X_test = torch.from_numpy(X_test).float().reshape(-1, n_features_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make a new auto encoder that uses n_dim to make a n_layers with n_dim in the middle\n",
    "# lets make a function that given a desired depth will report a appropriate topology \n",
    "# example 3 layers 11 features would be 11, 7, 3\n",
    "\n",
    "def get_topology(n_features, depth, out_features=3):\n",
    "    topology = []\n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            topology.append(n_features)\n",
    "        else:\n",
    "            topology.append(int(topology[i-1] / 2))\n",
    "            if topology[i] < out_features:\n",
    "                topology[i] = out_features\n",
    "    topology.append(out_features)\n",
    "    return topology\n",
    "\n",
    "# test\n",
    "get_topology(11, 3,)\n",
    "4284/204\n",
    "class autoNN(nn.Module):\n",
    "    def __init__(self, n_inputs=11, n_dimensions=3, n_layers=3):\n",
    "        super(autoNN, self).__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_dimensions = n_dimensions\n",
    "        self.n_layers = n_layers\n",
    "        self.topology = get_topology(n_inputs, n_layers, n_dimensions)\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        print(self.topology)\n",
    "        for i in range(n_layers):\n",
    "            if i == 0:\n",
    "                self.encoder.append(nn.Linear(n_inputs, self.topology[i+1]))\n",
    "            else:\n",
    "                self.encoder.append(nn.Linear(self.topology[i], self.topology[i+1]))\n",
    "            self.encoder.append(nn.ReLU())\n",
    "        self.encoder = self.encoder[:-1]\n",
    "        # invert the encoder using the encoder object\n",
    "        for i in self.encoder[::-1]:\n",
    "            if isinstance(i, nn.Linear):\n",
    "                self.decoder.append(nn.Linear(i.out_features, i.in_features))\n",
    "                self.decoder.append(nn.ReLU())\n",
    "        self.decoder = self.decoder[:-1]\n",
    "                   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # encode the input\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        # decode the input\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = x.reshape(-1, self.n_inputs)\n",
    "        print(x.shape)\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def decode(self, x):\n",
    "        x = x.reshape(-1, self.n_inputs)\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 29, 14, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "autoNN(\n",
       "  (encoder): ModuleList(\n",
       "    (0): Linear(in_features=58, out_features=29, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=29, out_features=14, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=14, out_features=3, bias=True)\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): Linear(in_features=3, out_features=14, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=14, out_features=29, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=29, out_features=58, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append y data to the end of the x data\n",
    "X_to_code = torch.cat((X_train, y_train), dim=1)\n",
    "auto = autoNN(n_inputs=n_features_train+1, n_dimensions=3, n_layers=3)\n",
    "auto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[39m=\u001b[39m kmk\u001b[39m.\u001b[39;49mrun_Pytorch(auto, X_to_code, X_to_code, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/kmodels/kmodels.py:27\u001b[0m, in \u001b[0;36mrun_Pytorch\u001b[0;34m(model, X_train, Y_train, n_epochs, learning_rate, batch_size, device, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m optimizer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, weight_decay\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m losses \u001b[39m=\u001b[39m train_pytorch(model, \n\u001b[1;32m     28\u001b[0m              X_train, \n\u001b[1;32m     29\u001b[0m              Y_train,\n\u001b[1;32m     30\u001b[0m              n_epochs\u001b[39m=\u001b[39;49mn_epochs,\n\u001b[1;32m     31\u001b[0m              batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     32\u001b[0m              learning_rate\u001b[39m=\u001b[39;49mlearning_rate)\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/kmodels/kmodels.py:73\u001b[0m, in \u001b[0;36mtrain_pytorch\u001b[0;34m(model, X_train, Y_train, n_epochs, batch_size, learning_rate, device, optimizer)\u001b[0m\n\u001b[1;32m     71\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     72\u001b[0m batches \u001b[39m=\u001b[39m batch_data(X_train, batch_size)\n\u001b[0;32m---> 73\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     74\u001b[0m \u001b[39m#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m loss_func \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mMSELoss()\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "losses = kmk.run_Pytorch(auto, X_to_code, X_to_code, n_epochs=1000, batch_size=1000, learning_rate=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
